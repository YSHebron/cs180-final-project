{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%config InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Fetching all Air Quality datasets into their dataframes\n",
    "# Perform immediate concatenation per year\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize datasets using co (do not add extra datasets to dir)\n",
    "dir = 'CAdata/'\n",
    "colidx = [0,2,4,17]                             # column indexes to use\n",
    "innerkeys = ['Date', 'Site ID', 'COUNTY']       # Merge on Date, Site ID, and County\n",
    "dataA2020 = pd.read_csv(dir + 'cf-2020-co.csv', parse_dates=True, usecols=colidx)\n",
    "dataA2021 = pd.read_csv(dir + 'cf-2021-co.csv', parse_dates=True, usecols=colidx)\n",
    "dataA2022 = pd.read_csv(dir + 'cf-2022-co.csv', parse_dates=True, usecols=colidx)\n",
    "\n",
    "with os.scandir(dir) as datasets:\n",
    "    for dataset in datasets:\n",
    "        if dataset.is_file() and 'co' not in dataset.name:\n",
    "            temp = pd.read_csv(dataset, parse_dates=True, usecols=colidx)\n",
    "            if '2020' in dataset.name:\n",
    "                dataA2020 = pd.merge(dataA2020, temp, how='outer', on=innerkeys)\n",
    "            elif '2021' in dataset.name:\n",
    "                dataA2021 = pd.merge(dataA2021, temp, how='outer', on=innerkeys)\n",
    "            elif '2022' in dataset.name:\n",
    "                dataA2022 = pd.merge(dataA2022, temp, how='outer', on=innerkeys)\n",
    "\n",
    "# Parse Dates to date\n",
    "dataA2020['Date'] = pd.to_datetime(dataA2020['Date'])\n",
    "dataA2021['Date'] = pd.to_datetime(dataA2021['Date'])\n",
    "dataA2022['Date'] = pd.to_datetime(dataA2022['Date'])\n",
    "\n",
    "# Group data by Date and Site ID, then by Date again to remove the Site ID feature\n",
    "# Result would be mean measurements per day\n",
    "# QUESTION: If regression is poor, let's do another one wherein we don't group by date\n",
    "dataA2020 = dataA2020.groupby(by=['Date', 'Site ID']).mean().groupby(by=['Date']).mean()\n",
    "dataA2021 = dataA2021.groupby(by=['Date', 'Site ID']).mean().groupby(by=['Date']).mean()\n",
    "dataA2022 = dataA2022.groupby(by=['Date', 'Site ID']).mean().groupby(by=['Date']).mean()\n",
    "\n",
    "dataA = pd.concat([dataA2020, dataA2021, dataA2022])    # Combine the three datasets\n",
    "\n",
    "print(\"Combined dataset (Date set as index)\")\n",
    "dataA.head()\n",
    "\n",
    "new_names = ['CO conc (ppm)', 'NO2 conc (ppb)', 'O3 conc (ppm)',\n",
    "             'Pb conc (ug/m3 SC)', 'PM10 conc (ug/m3 SC)',\n",
    "             'PM2.5 conc (ug/m3 LC)', 'SO2 conc (ppb)']\n",
    "\n",
    "# Rename columns\n",
    "for i in range(len(new_names)):\n",
    "    dataA.rename(columns={dataA.columns[i]: new_names[i]}, inplace=True)\n",
    "\n",
    "print(\"Columns renamed:\")\n",
    "dataA.head()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Deciding whether to drop or impute null values, so we check how many null values there are.\n",
    "# Dataset A impute\n",
    "print(\"A: Number of entries with null values:\", dataA.isna().any(axis=1).sum())\n",
    "print(\"A: Number of entries:\", dataA.shape[0])\n",
    "\n",
    "# These imports are important, imputer relies on them.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer   # Important!\n",
    "from sklearn.impute import IterativeImputer     # default imputer is BayesianRidge\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Other estimators (estimator = func()) to try\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Initialize imputer\n",
    "imp = IterativeImputer(max_iter=100, random_state=1, verbose=True)\n",
    "dataA[:] = imp.fit_transform(dataA)\n",
    "\n",
    "print(\"After imputation:\")\n",
    "dataA.head()\n",
    "print(\"A: Number of entries with null values after impute:\", dataA.isna().any(axis=1).sum())\n",
    "print(\"A: Number of entries:\", dataA.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colidx = [0,1,2,5,6]     # column indexes to use (based on looking at dataB)\n",
    "dataB = pd.read_csv('datasets/us_covid_cases_and_deaths_by_state.csv', parse_dates=True, usecols=colidx)\n",
    "sum_new_cases = dataB['new_case'] + dataB['pnew_case']\n",
    "dataB.drop(['new_case', 'pnew_case'], axis=1, inplace=True)\n",
    "dataB['sum_new_cases'] = sum_new_cases\n",
    "dataB.head()\n",
    "\n",
    "dataB.columns = ['Date', 'State', 'Total Cases', 'Sum New Cases']\n",
    "\n",
    "# Filter dataset B\n",
    "dataB = dataB[dataB['State'] == 'CA']\n",
    "dataB.head()\n",
    "\n",
    "# Use Date as index, also drop the State\n",
    "print(\"Dateset B finalized\")\n",
    "dataB['Date'] = pd.to_datetime(dataB['Date'])\n",
    "dataB.set_index('Date', inplace=True)\n",
    "dataB.sort_index(inplace=True)\n",
    "dataB.drop('State', axis=1, inplace=True)\n",
    "dataB.info()\n",
    "dataB.head()\n",
    "\n",
    "# Filter dataA with temporal restriction given by dataB\n",
    "dataA = dataA[(dataA.index >= dataB.index.min()) &\n",
    "              (dataA.index <= dataB.index.max())]\n",
    "\n",
    "print(\"Filtered Dataset A\")\n",
    "dataA.head()\n",
    "\n",
    "# With the printouts below, we find that there's no need to impute.\n",
    "print(\"B: Number of entries with null values:\", dataB.isna().any(axis=1).sum())\n",
    "print(\"B: Number of entries:\", dataB.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merging the two datasets (dataA & dataB)\n",
    "data = dataA.merge(dataB, left_index=True, right_index=True)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# GENERATE SCATTERPLOTS FOR EDUCATED GUESSES OF WHAT COLUMNS TO USE\n",
    "# DYNAMIC PRUNING\n",
    "# IDEA: We focus on ambient level of pollutants and ignore sudden spikes in COVID-19 case data (i.e. data dumps).\n",
    "# We also remove Dates where there are no new infections as their volume skews the data alot.\n",
    "data = data[(data['Sum New Cases'] <= 50000) & (data['Sum New Cases'] > 0)]\n",
    "data = data[data['CO conc (ppm)'] <= 1.0]\n",
    "# # data = data[data['NO2 conc (ppb)'] ]\n",
    "data = data[data['O3 conc (ppm)'] > 0.035]\n",
    "data = data[data['Pb conc (ug/m3 SC)'] < 0.03]\n",
    "data = data[data['PM10 conc (ug/m3 SC)'] < 100]\n",
    "data = data[data['PM2.5 conc (ug/m3 LC)'] < 20]\n",
    "data = data[data['SO2 conc (ppb)'] < 2.0]\n",
    "\n",
    "for label in data.columns:\n",
    "    if label in ['Sum New Cases', 'Total Cases']: continue\n",
    "    sns.set_style('dark')\n",
    "    sns.relplot(x=label, y='Sum New Cases', data=data, height=3.8, aspect=1.8, kind='scatter')\n",
    "\n",
    "print(\"Number of entries remaining after pruning:\", data.shape[0])\n",
    "\n",
    "# DROP COLUMNS HERE\n",
    "data.drop(columns=['CO conc (ppm)', 'NO2 conc (ppb)', 'O3 conc (ppm)'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(data.columns)-2, ncols=1, figsize=(16,64))\n",
    "\n",
    "i = 0\n",
    "for label in data.columns:\n",
    "    if label in [\"Sum New Cases\", \"Total Cases\"]: continue\n",
    "    sns.regplot(x=label, y='Sum New Cases', data=data, ci=95, scatter_kws={'s':100, 'facecolor':'red'}, ax=axs[i])\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "# PREPARE FEATURES AND TARGET DATA\n",
    "X = data.iloc[:,0:-1] # feature matrix\n",
    "y = data.iloc[:,-1] # target vector\n",
    "\n",
    "# PREPARE TRAIN AND TEST DATA\n",
    "# NOTE: random_state = 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# TODO: Hyperparameter tuning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "print(\"Coefficients:\", regressor.coef_)\n",
    "print(\"Intercept:\", regressor.intercept_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\"Actual\":y_test,\"Predicted\":y_pred})\n",
    "comparison_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "residuals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_test, y = y_pred, s=140)\n",
    "plt.xlabel('y_test data')\n",
    "plt.ylabel('Predictions')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE:', mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE\",mean_squared_error(y_test,y_pred))\n",
    "\n",
    "import numpy as np\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(\"R2 Score:\", r2)      # We use this as our main metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "NewData = data\n",
    "NewData"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For CO conc (ppm) & Sum New Cases\n",
    "## Perform regression modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import calendar\n",
    "\n",
    "# Convert datetime to int\n",
    "#x = data['Date'].values.astype(int) / 10**9  # Convert to seconds (UNIX epoch start)\n",
    "#x = x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "x = NewData['CO conc (ppm)']\n",
    "y = NewData['Sum New Cases']\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Linear regression model\n",
    "#--------------------------------------------------------------\n",
    "# Stastical approach\n",
    "x_lms = sm.add_constant(x)\n",
    "linear_model_stat = sm.OLS(y, x_lms)\n",
    "lms_results = linear_model_stat.fit()\n",
    "p_values = lms_results.pvalues[1:]\n",
    "\n",
    "# Machine learning approach (no p-values)\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(x_lms, y)\n",
    "y_linear_pred = linear_model.predict(x_lms)\n",
    "\n",
    "# Calculate R2 and RMSE for linear regression model\n",
    "linear_r2 = r2_score(y, y_linear_pred)\n",
    "linear_rmse = np.sqrt(mean_squared_error(y, y_linear_pred))\n",
    "\n",
    "print(\"Model Evaluation\")\n",
    "print(\"\\nLinear Regression: RMSE=%.2f, R2=%.2f\" % (linear_rmse, linear_r2))\n",
    "for i, p_value in enumerate(p_values.index):\n",
    "  print(f'P({p_value}): {p_values[i]}')\n",
    "\n",
    "if any(p_values <= 0.05):\n",
    "  print(\"There is a significant relationship between the predictor and the response\\n\")\n",
    "else:\n",
    "  print(\"There is no significant relationship between the predictor and the response\\n\")\n",
    "\n",
    "\n",
    "# Plot the model\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "xtt = NewData['CO conc (ppm)']#.dt.strftime('%Y-%m-%d')\n",
    "scatter_actual = go.Scatter(x=xtt, y=y, mode='markers', name='Actual', marker=dict(color='blue', opacity=0.3))\n",
    "\n",
    "line_regression = go.Scatter(x=xtt, y=y_linear_pred, mode='lines', name='LR', line=dict(color='red', dash='dash'))\n",
    "\n",
    "data = [scatter_actual, line_regression]\n",
    "\n",
    "layout = go.Layout(xaxis=dict(title='CO conc (ppm)'),\n",
    "                   yaxis=dict(title='Sum New Cases'),\n",
    "                   title='Linear Regression Model for COVID-19 New Cases & CO conc (ppm)',\n",
    "                   showlegend=True,\n",
    "                   height=600)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For NO2 conc (ppb) & Sum New Cases\n",
    "## Perform regression modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import calendar\n",
    "\n",
    "# Convert datetime to int\n",
    "#x = data['Date'].values.astype(int) / 10**9  # Convert to seconds (UNIX epoch start)\n",
    "#x = x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "x = NewData['NO2 conc (ppb)']\n",
    "y = NewData['Sum New Cases']\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Linear regression model\n",
    "#--------------------------------------------------------------\n",
    "# Stastical approach\n",
    "x_lms = sm.add_constant(x)\n",
    "linear_model_stat = sm.OLS(y, x_lms)\n",
    "lms_results = linear_model_stat.fit()\n",
    "p_values = lms_results.pvalues[1:]\n",
    "\n",
    "# Machine learning approach (no p-values)\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(x_lms, y)\n",
    "y_linear_pred = linear_model.predict(x_lms)\n",
    "\n",
    "# Calculate R2 and RMSE for linear regression model\n",
    "linear_r2 = r2_score(y, y_linear_pred)\n",
    "linear_rmse = np.sqrt(mean_squared_error(y, y_linear_pred))\n",
    "\n",
    "print(\"Model Evaluation\")\n",
    "print(\"\\nLinear Regression: RMSE=%.2f, R2=%.2f\" % (linear_rmse, linear_r2))\n",
    "for i, p_value in enumerate(p_values.index):\n",
    "  print(f'P({p_value}): {p_values[i]}')\n",
    "\n",
    "if any(p_values <= 0.05):\n",
    "  print(\"There is a significant relationship between the predictor and the response\\n\")\n",
    "else:\n",
    "  print(\"There is no significant relationship between the predictor and the response\\n\")\n",
    "\n",
    "\n",
    "# Plot the model\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "xtt = NewData['NO2 conc (ppb)']#.dt.strftime('%Y-%m-%d')\n",
    "scatter_actual = go.Scatter(x=xtt, y=y, mode='markers', name='Actual', marker=dict(color='blue', opacity=0.3))\n",
    "\n",
    "line_regression = go.Scatter(x=xtt, y=y_linear_pred, mode='lines', name='LR', line=dict(color='red', dash='dash'))\n",
    "\n",
    "data = [scatter_actual, line_regression]\n",
    "\n",
    "layout = go.Layout(xaxis=dict(title='NO2 conc (ppb)'),\n",
    "                   yaxis=dict(title='Sum New Cases'),\n",
    "                   title='Linear Regression Model for COVID-19 New Cases & NO2 conc (ppb)',\n",
    "                   showlegend=True,\n",
    "                   height=600)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For O3 conc (ppm) & Sum New Cases\n",
    "## Perform regression modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import calendar\n",
    "\n",
    "# Convert datetime to int\n",
    "#x = data['Date'].values.astype(int) / 10**9  # Convert to seconds (UNIX epoch start)\n",
    "#x = x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "x = NewData['O3 conc (ppm)']\n",
    "y = NewData['Sum New Cases']\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Linear regression model\n",
    "#--------------------------------------------------------------\n",
    "# Stastical approach\n",
    "x_lms = sm.add_constant(x)\n",
    "linear_model_stat = sm.OLS(y, x_lms)\n",
    "lms_results = linear_model_stat.fit()\n",
    "p_values = lms_results.pvalues[1:]\n",
    "\n",
    "# Machine learning approach (no p-values)\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(x_lms, y)\n",
    "y_linear_pred = linear_model.predict(x_lms)\n",
    "\n",
    "# Calculate R2 and RMSE for linear regression model\n",
    "linear_r2 = r2_score(y, y_linear_pred)\n",
    "linear_rmse = np.sqrt(mean_squared_error(y, y_linear_pred))\n",
    "\n",
    "print(\"Model Evaluation\")\n",
    "print(\"\\nLinear Regression: RMSE=%.2f, R2=%.2f\" % (linear_rmse, linear_r2))\n",
    "for i, p_value in enumerate(p_values.index):\n",
    "  print(f'P({p_value}): {p_values[i]}')\n",
    "\n",
    "if any(p_values <= 0.05):\n",
    "  print(\"There is a significant relationship between the predictor and the response\\n\")\n",
    "else:\n",
    "  print(\"There is no significant relationship between the predictor and the response\\n\")\n",
    "\n",
    "\n",
    "# Plot the model\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "xtt = NewData['O3 conc (ppm)']#.dt.strftime('%Y-%m-%d')\n",
    "scatter_actual = go.Scatter(x=xtt, y=y, mode='markers', name='Actual', marker=dict(color='blue', opacity=0.3))\n",
    "\n",
    "line_regression = go.Scatter(x=xtt, y=y_linear_pred, mode='lines', name='LR', line=dict(color='red', dash='dash'))\n",
    "\n",
    "data = [scatter_actual, line_regression]\n",
    "\n",
    "layout = go.Layout(xaxis=dict(title='O3 conc (ppm)'),\n",
    "                   yaxis=dict(title='Sum New Cases'),\n",
    "                   title='Linear Regression Model for COVID-19 New Cases & O3 conc (ppm)',\n",
    "                   showlegend=True,\n",
    "                   height=600)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
